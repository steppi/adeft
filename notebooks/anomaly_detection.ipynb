{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection\n",
    "\n",
    "The `AdeftAnomalyDetector` is an experimental class for detecting if there are texts being incorrectly grounded to a gene. The plan is to use a `OneClassSVM` trained on Entrez texts for a given gene. This can then be used to search for anomalous papers containing texts that have been grounded to that gene. If a paper is anomalous we have cause to believe the grounding is incorrect. Further work is needed to validate if this method is effective. This notebook demonstrates how to use the `AdeftAnomalyDetector` on a small set of example data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import required packages and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from adeft.modeling.investigate import AdeftAnomalyDetector\n",
    "\n",
    "\n",
    "with open('data/example_training_data.json') as f:\n",
    "    ir_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ir_data` is a dictionary with two keys, `'texts'` and `'labels'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = ir_data['texts'], ir_data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`texts` is a list of training texts and `labels` is a list of the corresponding labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split these up into texts referring to the insulin receptor and texts referring to some other expansion of IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_texts = [text for text, label in zip(texts, labels) if label == 'HGNC:6091']\n",
    "other_texts = [text for text, label in zip(texts, labels) if label != 'HGNC:6091']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 101 texts where IR refers to insulin receptor and 399 texts where it refers to something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 399\n"
     ]
    }
   ],
   "source": [
    "print(len(gene_texts), len(other_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The we instantiate the anomaly detector. The first argument is the HGNC symbol for the gene of interest and the second argument is a list of synonyms. Here we use \"IR\" as the only synonym. **When we use the `AdeftAnomalyDetector` for real examples, the list of synonyms should be a filtered list of texts that are being grounded to the gene of interest.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_detector = AdeftAnomalyDetector('INSR', ['IR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the `AdeftClassifier` we can use a `cv` method to perform a grid search. For now you'll have to enter a param_grid using the syntax for sklearn pipelines as shown below. In the future you will be able to use parameter names directly as keys. The parameter `nu` for the `OneClassSVM` is an upper bound on the fraction of training errors that can be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_features': [10, 50],\n",
    "              'ngram_range': [(1, 1)],\n",
    "              'nu': [0.2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scheme will divides `gene_texts` into folds in the typical fashion with each test fold being augmented with a random sample of texts from `other_texts`. The parameter `k` controls the number of non-gene texts to add to each test fold. The following examples use three fold cross validation and add 5, 10, 50, and 100 negative texts per fold. This is useful for seeing how results vary depending on the level of ambiguity of a term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_detector.cv(gene_texts, other_texts, param_grid, n_jobs=4, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = anomaly_detector.grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.04379511, 0.03231721]),\n",
       " 'std_fit_time': array([0.011137  , 0.00377295]),\n",
       " 'mean_score_time': array([0.07023048, 0.06568398]),\n",
       " 'std_score_time': array([0.00689565, 0.00586244]),\n",
       " 'param_oc_svm__nu': masked_array(data=[0.2, 0.2],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_tfidf__max_features': masked_array(data=[10, 50],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1)],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'oc_svm__nu': 0.2,\n",
       "   'tfidf__max_features': 10,\n",
       "   'tfidf__ngram_range': (1, 1)},\n",
       "  {'oc_svm__nu': 0.2,\n",
       "   'tfidf__max_features': 50,\n",
       "   'tfidf__ngram_range': (1, 1)}],\n",
       " 'split0_test_sens': array([0.8625, 0.7625]),\n",
       " 'split1_test_sens': array([0.875 , 0.7125]),\n",
       " 'split2_test_sens': array([0.7875, 0.6375]),\n",
       " 'split3_test_sens': array([0.875, 0.725]),\n",
       " 'split4_test_sens': array([0.78481013, 0.72151899]),\n",
       " 'mean_test_sens': array([0.83696203, 0.7118038 ]),\n",
       " 'std_test_sens': array([0.04174273, 0.04089051]),\n",
       " 'rank_test_sens': array([1, 2], dtype=int32),\n",
       " 'split0_test_spec': array([0.78571429, 0.76      ]),\n",
       " 'split1_test_spec': array([0.66666667, 0.79310345]),\n",
       " 'split2_test_spec': array([0.77272727, 0.85294118]),\n",
       " 'split3_test_spec': array([0.66666667, 0.73333333]),\n",
       " 'split4_test_spec': array([0.80952381, 0.84615385]),\n",
       " 'mean_test_spec': array([0.74025974, 0.79710636]),\n",
       " 'std_test_spec': array([0.06123667, 0.04686808]),\n",
       " 'rank_test_spec': array([2, 1], dtype=int32),\n",
       " 'split0_test_se': array([0.78571429, 0.76      ]),\n",
       " 'split1_test_se': array([0.66666667, 0.79310345]),\n",
       " 'split2_test_se': array([0.77272727, 0.85294118]),\n",
       " 'split3_test_se': array([0.66666667, 0.73333333]),\n",
       " 'split4_test_se': array([0.80952381, 0.84615385]),\n",
       " 'mean_test_se': array([0.74025974, 0.79710636]),\n",
       " 'std_test_se': array([0.06123667, 0.04686808]),\n",
       " 'rank_test_se': array([2, 1], dtype=int32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.533410141937465"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_detector.specificity + anomaly_detector.sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19801980198019803"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(anomaly_detector.predict(gene_texts))/len(gene_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7017543859649122"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(anomaly_detector.predict(other_texts))/len(other_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 300\n",
      "0.5564541227024271 0.6420210092052625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7094138987738328, 0.869828708646096)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_detector.confidence_interval(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.501704891572853"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_detector.best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metric used is balanced accuracy. It is the average of the recall values for each class. As expected, this score does not vary with the number of anomalous examples in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are no negative examples available, you can train on only the positive examples using the `train` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_detector.train(gene_texts, nu=0.05, max_features=100, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once trained, predictions can be made using the predict method. A prediction of 1.0 will be made for examples the classifier believes to be anomalous with a prediction of 0.0 being made for other examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = anomaly_detector.predict(gene_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = anomaly_detector.predict(other_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 of the 101 gene texts were predicted to be anomalous while 358 of the 399 other texts were predicted to be anomalous\n"
     ]
    }
   ],
   "source": [
    "print('%d of the %d gene texts were predicted to be anomalous while %d of the %d other texts were'\n",
    "      ' predicted to be anomalous' % (sum(preds1), len(gene_texts), sum(preds2), len(other_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.798"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "399/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
